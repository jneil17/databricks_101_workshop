{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9765335-5a3f-477b-91e6-2aefc5cbe612",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DLT Bronze Table: Raw Qualifying Results"
    }
   },
   "source": [
    "## 🏎️ F1 Delta Live Tables Pipeline\n",
    "\n",
    "This notebook demonstrates Delta Live Tables (DLT) concepts, but the **actual runnable pipeline** is located in:\n",
    "\n",
    "### 📂 **`06_Formula1_Declarative_Pipeline`**\n",
    "\n",
    "**👉 Navigate there now to run the pre-built F1 qualifying data pipeline!**\n",
    "\n",
    "---\n",
    "\n",
    "### 📸 Screenshot Placeholder\n",
    "*[ADD SCREENSHOT: Navigation to 06_Formula1_Declarative_Pipeline folder]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b267df2-2a54-4a9d-994b-e02ee4c9c943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 🚀 Using the Existing Pipeline\n",
    "\n",
    "The **`06_Formula1_Declarative_Pipeline`** contains a complete, ready-to-run DLT pipeline with:\n",
    "\n",
    "* 🥉 **Bronze CDC Table**: Streaming ingestion of F1 sprint qualifying data using Autoloader from cloud storage (`/Volumes/main/default/streaming_formula1/`)\n",
    "* 🔧 **Data Quality View**: Cleansed CDC data with expectations to drop invalid records (null rescued data, missing track/driver info)\n",
    "* 📊 **Streaming Table**: Final bronze table with Change Data Capture flow using Track + Driver as keys, sequenced by Q1 times\n",
    "* ⚡ **Auto CDC Flow**: Automatically handles inserts, updates, and deletes based on qualifying time changes\n",
    "\n",
    "### 📸 Screenshot Placeholder\n",
    "*[ADD SCREENSHOT: 06_Formula1_Declarative_Pipeline notebook content]*\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 Optional: Create Your Own Pipeline\n",
    "\n",
    "If you want to create a **new pipeline** instead:\n",
    "\n",
    "1. **Workflows** → **Delta Live Tables** → **Create Pipeline**\n",
    "2. **Source**: Select `06_Formula1_Declarative_Pipeline` notebook\n",
    "3. **Target**: `main.default` (or your preferred catalog/schema)\n",
    "4. **Click \"Create\"** and then **\"Start\"**\n",
    "\n",
    "### 📸 Screenshot Placeholder\n",
    "*[ADD SCREENSHOT: DLT Pipeline creation form]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a78ae96d-c562-450a-b1cf-d7650d10f7f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 🚀 Next Steps\n",
    "\n",
    "Ready to explore AI-powered features and advanced analytics?\n",
    "\n",
    "### Immediate Actions:\n",
    "1. **🔄 Create Your DLT Pipeline:**\n",
    "   - Go to Workflows → Delta Live Tables → Create Pipeline\n",
    "   - Use this notebook as the source\n",
    "   - Configure with Serverless compute\n",
    "\n",
    "2. **📊 Monitor Pipeline Execution:**\n",
    "   - Watch automatic dependency resolution\n",
    "   - Check data quality expectation results\n",
    "   - Explore generated lineage graphs\n",
    "\n",
    "3. **➡️ Next Notebook:** [06_AI_Agent_Bricks.ipynb](06_AI_Agent_Bricks.ipynb)\n",
    "   - Explore AI Agents and intelligent applications\n",
    "   - Build F1 Q&A chatbots with your data\n",
    "\n",
    "### 🎯 Best Practices Checklist:\n",
    "- ✅ **Start simple** with basic Bronze → Silver → Gold\n",
    "- ✅ **Add expectations gradually** as you understand your data\n",
    "- ✅ **Use descriptive table names** for clarity\n",
    "- ✅ **Document transformations** with comments\n",
    "- ✅ **Monitor data quality** trends over time\n",
    "- ✅ **Test expectations** before production deployment\n",
    "\n",
    "### 💡 Pro Tips:\n",
    "- **🔧 Start with `@dlt.expect()`** to understand data patterns\n",
    "- **📊 Use DLT dashboards** for quality monitoring\n",
    "- **⚡ Leverage Serverless** for cost-effective execution\n",
    "- **🔄 Design for incremental processing** from day one\n",
    "\n",
    "**🔄 Your data pipelines are now production-ready! 🚀**"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06_Declarative_Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
