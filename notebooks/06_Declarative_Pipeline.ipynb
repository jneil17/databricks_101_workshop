{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc678b8a-15c9-416a-8345-ab6806ace4c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ğŸï¸ Formula 1 Qualifying Results DLT Pipeline\n",
    "\n",
    "This notebook demonstrates a simple Delta Live Tables (DLT) pipeline for Formula 1 qualifying results. The pipeline has three layers:\n",
    "\n",
    "* **Bronze**: Ingests raw data from CSV files\n",
    "* **Silver**: Cleans and standardizes the data\n",
    "* **Gold**: Aggregates and summarizes for reporting\n",
    "\n",
    "Each layer builds on the previous one, making the data more useful and reliable for analytics. The code and explanations are designed for new joiners to quickly understand how DLT works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9765335-5a3f-477b-91e6-2aefc5cbe612",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DLT Bronze Table: Raw Qualifying Results"
    }
   },
   "source": [
    "## ğŸ¥‡ Gold Layer: Analytics-Ready Aggregations\n",
    "\n",
    "Gold tables provide business-ready analytics with complex aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04b94a8a-7fca-4840-b97f-8de05befec1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install dlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b267df2-2a54-4a9d-994b-e02ee4c9c943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"bronze_qualifying_results\",\n",
    "    comment=\"Raw Formula 1 qualifying results from CSV file.\"\n",
    ")\n",
    "def bronze_qualifying_results():\n",
    "    return (\n",
    "        spark.read.format(\"csv\")\n",
    "        .option(\"header\", True)\n",
    "        .load(\"/Volumes/main/default/formula1/Formula1_2025Season_QualifyingResults.csv\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8df24d34-2358-4f27-809f-bfe696868ba0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"dlt_gold_driver_stats\",\n",
    "    comment=\"DLT Gold: Comprehensive driver career statistics and performance metrics\"\n",
    ")\n",
    "@dlt.expect(\"drivers_with_races\", \"total_races > 0\")\n",
    "def gold_driver_stats():\n",
    "    \"\"\"\n",
    "    Calculate comprehensive driver career statistics.\n",
    "    Aggregates from clean silver tables to create analytics-ready data.\n",
    "    \"\"\"\n",
    "    drivers = dlt.read(\"dlt_silver_drivers_clean\")\n",
    "    results = dlt.read(\"dlt_silver_results_clean\")\n",
    "    \n",
    "    return (\n",
    "        drivers.alias(\"d\")\n",
    "        .join(results.alias(\"r\"), col(\"d.driver_id\") == col(\"r.driver_id\"), \"inner\")\n",
    "        .groupBy(\n",
    "            col(\"d.driver_id\"),\n",
    "            col(\"d.full_name\"),\n",
    "            col(\"d.nationality\"),\n",
    "            col(\"d.current_age\"),\n",
    "            col(\"d.birth_date\")\n",
    "        )\n",
    "        .agg(\n",
    "            count(\"r.result_id\").alias(\"total_races\"),\n",
    "            sum(\"r.points_scored\").alias(\"career_points\"),\n",
    "            sum(when(col(\"r.race_winner\"), 1).otherwise(0)).alias(\"wins\"),\n",
    "            sum(when(col(\"r.podium_finish\"), 1).otherwise(0)).alias(\"podiums\"),\n",
    "            sum(when(col(\"r.scored_points\"), 1).otherwise(0)).alias(\"points_finishes\"),\n",
    "            avg(\"r.finish_position\").alias(\"avg_finish_position\"),\n",
    "            min(\"r.finish_position\").alias(\"best_finish\"),\n",
    "            max(\"r.finish_position\").alias(\"worst_finish\"),\n",
    "            sum(\"r.laps_completed\").alias(\"total_laps\"),\n",
    "            # Performance ratios\n",
    "            round(sum(\"r.points_scored\") / count(\"r.result_id\"), 2).alias(\"points_per_race\"),\n",
    "            round(sum(when(col(\"r.race_winner\"), 1).otherwise(0)) * 100.0 / count(\"r.result_id\"), 2).alias(\"win_percentage\"),\n",
    "            round(sum(when(col(\"r.podium_finish\"), 1).otherwise(0)) * 100.0 / count(\"r.result_id\"), 2).alias(\"podium_percentage\"),\n",
    "            # Data lineage\n",
    "            current_timestamp().alias(\"calculated_at\"),\n",
    "            lit(\"dlt_gold_aggregation\").alias(\"calculation_method\")\n",
    "        )\n",
    "        .filter(col(\"total_races\") >= 1)  # Only drivers with actual race participation\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6e06e02-967b-48d7-8ec9-419a62571118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ğŸ¥‰ Bronze Table: Raw Ingestion\n",
    "\n",
    "The bronze table is the first step in our pipeline. It simply loads the raw qualifying results from the CSV file into a Delta table. No cleaning or transformation is done hereâ€”this layer is all about capturing the original data as-is, so we always have a source of truth to refer back to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc2d192d-c41f-4ad5-ae5d-3ed8b678c23b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"dlt_gold_top_performers\",\n",
    "    comment=\"DLT Gold: Top performing drivers across different performance categories\"\n",
    ")\n",
    "@dlt.expect(\"performance_categories\", \"performance_tier IS NOT NULL\")\n",
    "def gold_top_performers():\n",
    "    \"\"\"\n",
    "    Create performance tiers and identify top performers.\n",
    "    Builds on driver stats to create business-friendly categorizations.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        dlt.read(\"dlt_gold_driver_stats\")\n",
    "        .select(\n",
    "            col(\"driver_id\"),\n",
    "            col(\"full_name\"),\n",
    "            col(\"nationality\"),\n",
    "            col(\"total_races\"),\n",
    "            col(\"career_points\"),\n",
    "            col(\"wins\"),\n",
    "            col(\"podiums\"),\n",
    "            col(\"points_per_race\"),\n",
    "            col(\"win_percentage\"),\n",
    "            col(\"podium_percentage\"),\n",
    "            # Create performance tiers\n",
    "            when(col(\"wins\") >= 20, \"F1 Legend\")\n",
    "            .when(col(\"wins\") >= 5, \"Race Winner\")\n",
    "            .when(col(\"podiums\") >= 10, \"Podium Regular\")\n",
    "            .when(col(\"career_points\") >= 100, \"Points Scorer\")\n",
    "            .when(col(\"total_races\") >= 20, \"Veteran\")\n",
    "            .otherwise(\"Rookie\").alias(\"performance_tier\"),\n",
    "            # Excellence indicators\n",
    "            when(col(\"win_percentage\") >= 25, \"Elite Winner\")\n",
    "            .when(col(\"podium_percentage\") >= 50, \"Consistent Podium\")\n",
    "            .when(col(\"points_per_race\") >= 5, \"Strong Performer\")\n",
    "            .otherwise(\"Developing\").alias(\"consistency_rating\"),\n",
    "            # Experience categorization\n",
    "            when(col(\"total_races\") >= 200, \"Ultra Veteran\")\n",
    "            .when(col(\"total_races\") >= 100, \"Veteran\")\n",
    "            .when(col(\"total_races\") >= 50, \"Experienced\")\n",
    "            .otherwise(\"Newcomer\").alias(\"experience_level\"),\n",
    "            col(\"calculated_at\"),\n",
    "            current_timestamp().alias(\"categorized_at\")\n",
    "        )\n",
    "        .filter(col(\"total_races\") >= 5)  # Focus on drivers with meaningful careers\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9106ceb-a9cb-4b49-b221-2a73bebbf350",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ğŸ“Š Data Quality Expectations Explained\n",
    "\n",
    "DLT provides powerful data quality features through **expectations**:\n",
    "\n",
    "### ğŸ¯ Expectation Types:\n",
    "\n",
    "#### 1. `@dlt.expect()`\n",
    "```python\n",
    "@dlt.expect(\"reasonable_birth_date\", \"date_of_birth >= '1900-01-01'\")\n",
    "```\n",
    "- **Behavior:** Records violation but continues processing\n",
    "- **Use case:** Data quality monitoring and alerts\n",
    "- **Result:** Violating records included in output with quality metrics tracked\n",
    "\n",
    "#### 2. `@dlt.expect_or_drop()`\n",
    "```python\n",
    "@dlt.expect_or_drop(\"valid_driver_id\", \"driver_id IS NOT NULL\")\n",
    "```\n",
    "- **Behavior:** Drops records that fail the expectation\n",
    "- **Use case:** Critical data quality requirements\n",
    "- **Result:** Only valid records in output table\n",
    "\n",
    "#### 3. `@dlt.expect_or_fail()`\n",
    "```python\n",
    "@dlt.expect_or_fail(\"critical_data\", \"COUNT(*) > 0\")\n",
    "```\n",
    "- **Behavior:** Stops pipeline execution if expectation fails\n",
    "- **Use case:** Critical business rules that cannot be violated\n",
    "- **Result:** Pipeline failure with clear error message\n",
    "\n",
    "### ğŸ“ˆ Quality Monitoring:\n",
    "- **Automatic dashboards** show data quality trends\n",
    "- **Alerting** when quality degrades\n",
    "- **Historical tracking** of data quality over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddbdb1c6-abcd-4e49-ab4f-875a6f24aa3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ğŸš€ DLT Pipeline Creation Guide\n",
    "\n",
    "### ğŸ“‹ How to Create a DLT Pipeline:\n",
    "\n",
    "#### 1. Navigate to Delta Live Tables ğŸ”„\n",
    "- Click **\"Workflows\"** in the left sidebar\n",
    "- Click **\"Delta Live Tables\"** tab\n",
    "- Click **\"Create Pipeline\"** button\n",
    "\n",
    "#### 2. Configure Pipeline Settings âš™ï¸\n",
    "```\n",
    "Pipeline Name: \"F1 Data Pipeline with DLT\"\n",
    "Description: \"Managed ETL pipeline for Formula 1 analytics with data quality\"\n",
    "```\n",
    "\n",
    "#### 3. Source Configuration ğŸ“\n",
    "- **Source Type:** `Notebook`\n",
    "- **Notebook Path:** Select this notebook (`05_Delta_Live_Pipeline.ipynb`)\n",
    "- **Source:** Your workspace location\n",
    "\n",
    "#### 4. Target Configuration ğŸ¯\n",
    "```\n",
    "Target Catalog: main\n",
    "Target Schema: default\n",
    "Storage Location: Managed (Unity Catalog)\n",
    "```\n",
    "\n",
    "#### 5. Compute Configuration âš¡\n",
    "```\n",
    "Cluster Mode: Serverless (recommended)\n",
    "Min Workers: 1\n",
    "Max Workers: 5 (auto-scaling)\n",
    "```\n",
    "\n",
    "#### 6. Advanced Settings ğŸ›ï¸\n",
    "- **Pipeline Mode:** `Triggered` (manual) or `Continuous` (streaming)\n",
    "- **Channel:** `Current` (latest features)\n",
    "- **Edition:** `Advanced` (for expectations and monitoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94766d20-cd07-4d63-9026-d7c507d6b4bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ğŸ”„ DLT vs Jobs: When to Use Each\n",
    "\n",
    "### ğŸ—ï¸ **Use Delta Live Tables When:**\n",
    "\n",
    "âœ… **Complex ETL with dependencies**\n",
    "- Multiple transformation layers (Bronze â†’ Silver â†’ Gold)\n",
    "- Automatic dependency resolution needed\n",
    "- Schema evolution and data quality critical\n",
    "\n",
    "âœ… **Data quality is paramount**\n",
    "- Need built-in expectations and monitoring\n",
    "- Automatic quarantine of bad data\n",
    "- Quality metrics and alerting required\n",
    "\n",
    "âœ… **Streaming and incremental processing**\n",
    "- Near real-time data processing\n",
    "- Change data capture (CDC) patterns\n",
    "- Efficient incremental updates\n",
    "\n",
    "âœ… **Team collaboration on pipelines**\n",
    "- Declarative code is easier to understand\n",
    "- Built-in lineage and documentation\n",
    "- Standardized patterns across teams\n",
    "\n",
    "### âš™ï¸ **Use Jobs When:**\n",
    "\n",
    "âœ… **Simple, scheduled tasks**\n",
    "- Single notebook execution\n",
    "- Basic data refresh operations\n",
    "- Notification and reporting workflows\n",
    "\n",
    "âœ… **Custom orchestration logic**\n",
    "- Complex conditional workflows\n",
    "- Integration with external systems\n",
    "- Custom retry and error handling\n",
    "\n",
    "âœ… **Ad-hoc or exploratory processing**\n",
    "- One-time data migration\n",
    "- Experimental data processing\n",
    "- Quick fixes and patches\n",
    "\n",
    "### ğŸ“Š **Feature Comparison:**\n",
    "\n",
    "| **Feature** | **Delta Live Tables** | **Jobs** |\n",
    "|-------------|----------------------|----------|\n",
    "| **Dependency Management** | âœ… Automatic | âš™ï¸ Manual |\n",
    "| **Data Quality** | âœ… Built-in expectations | âš™ï¸ Custom code |\n",
    "| **Streaming** | âœ… Native support | âš™ï¸ Structured streaming |\n",
    "| **Monitoring** | âœ… Automatic dashboards | âš™ï¸ Custom monitoring |\n",
    "| **Cost** | ğŸ’° DLT premium | ğŸ’° Standard compute |\n",
    "| **Flexibility** | ğŸ¯ Declarative patterns | ğŸ”§ Full control |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ba01a21-991e-4f42-ae0c-6a7dcee8e14e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ğŸ“ˆ Advanced DLT Features\n",
    "\n",
    "### ğŸ”„ **Change Data Capture (CDC)**\n",
    "```python\n",
    "@dlt.table\n",
    "def customers_cdc():\n",
    "    return dlt.read_stream(\"customers_raw\").apply_changes(\n",
    "        keys=[\"customer_id\"],\n",
    "        sequence_by=\"update_timestamp\",\n",
    "        apply_as_deletes=expr(\"operation = 'DELETE'\"),\n",
    "        except_column_list=[\"operation\", \"update_timestamp\"]\n",
    "    )\n",
    "```\n",
    "\n",
    "### ğŸ“Š **Pipeline Dependencies**\n",
    "```python\n",
    "# Automatic dependency resolution\n",
    "@dlt.table\n",
    "def downstream_table():\n",
    "    return dlt.read(\"upstream_table_1\").join(dlt.read(\"upstream_table_2\"))\n",
    "```\n",
    "\n",
    "### ğŸ¯ **Custom Expectations**\n",
    "```python\n",
    "@dlt.expect_or_fail(\"freshness_check\", \"max(update_time) > current_timestamp() - interval 1 day\")\n",
    "def time_sensitive_data():\n",
    "    return dlt.read(\"source_data\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28d03b60-66a9-4578-b5ef-d65d3e424d0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## âœ… Delta Live Tables Complete!\n",
    "\n",
    "**ğŸ‰ Outstanding! You've mastered Delta Live Tables fundamentals!**\n",
    "\n",
    "### What You've Accomplished:\n",
    "- âœ… **Built DLT pipeline** with Bronze, Silver, and Gold layers\n",
    "- âœ… **Implemented data quality expectations** for automatic monitoring\n",
    "- âœ… **Used declarative transformations** with automatic dependencies\n",
    "- âœ… **Learned DLT vs Jobs** comparison and use cases\n",
    "- âœ… **Explored advanced features** (CDC, streaming, quality monitoring)\n",
    "\n",
    "### ğŸ—ï¸ Your DLT Pipeline Architecture:\n",
    "```\n",
    "ğŸ“ Volume CSV Files\n",
    "    â†“ (Auto Loader)\n",
    "ğŸ¥‰ DLT Bronze Tables (Raw ingestion)\n",
    "    â†“ (Quality expectations)\n",
    "ğŸ¥ˆ DLT Silver Tables (Clean & validated)  \n",
    "    â†“ (Business aggregations)\n",
    "ğŸ¥‡ DLT Gold Tables (Analytics ready)\n",
    "```\n",
    "\n",
    "### ğŸ“Š Tables Created:\n",
    "- **Bronze:** `dlt_bronze_drivers`, `dlt_bronze_results`\n",
    "- **Silver:** `dlt_silver_drivers_clean`, `dlt_silver_results_clean`  \n",
    "- **Gold:** `dlt_gold_driver_stats`, `dlt_gold_top_performers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0f42309-935d-4c87-9b29-4da6dad04f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ğŸ“‹ Delta Live Tables Pipeline Summary\n",
    "\n",
    "This DLT pipeline will create the following tables:\n",
    "\n",
    "| Layer | Table | Description |\n",
    "|-------|------|-------------|\n",
    "| ğŸ¥‰ Bronze | `dlt_bronze_drivers` | Raw driver data ingestion |\n",
    "| ğŸ¥‰ Bronze | `dlt_bronze_results` | Raw results data ingestion |\n",
    "| ğŸ¥ˆ Silver | `dlt_silver_drivers_clean` | Validated driver data with quality expectations |\n",
    "| ğŸ¥ˆ Silver | `dlt_silver_results_clean` | Validated results data with quality expectations |\n",
    "| ğŸ¥‡ Gold | `dlt_gold_driver_stats` | Driver career statistics and aggregations |\n",
    "| ğŸ¥‡ Gold | `dlt_gold_top_performers` | Performance categorization and tiers |\n",
    "\n",
    "### Key Pipeline Features\n",
    "- ğŸ“Š **Data Quality**: Built-in expectations and monitoring\n",
    "- ğŸ”„ **Dependencies**: Automatic resolution and execution order\n",
    "- âš¡ **Compute**: Serverless managed infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a78ae96d-c562-450a-b1cf-d7650d10f7f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ğŸš€ Next Steps\n",
    "\n",
    "Ready to explore AI-powered features and advanced analytics?\n",
    "\n",
    "### Immediate Actions:\n",
    "1. **ğŸ”„ Create Your DLT Pipeline:**\n",
    "   - Go to Workflows â†’ Delta Live Tables â†’ Create Pipeline\n",
    "   - Use this notebook as the source\n",
    "   - Configure with Serverless compute\n",
    "\n",
    "2. **ğŸ“Š Monitor Pipeline Execution:**\n",
    "   - Watch automatic dependency resolution\n",
    "   - Check data quality expectation results\n",
    "   - Explore generated lineage graphs\n",
    "\n",
    "3. **â¡ï¸ Next Notebook:** [06_AI_Agent_Bricks.ipynb](06_AI_Agent_Bricks.ipynb)\n",
    "   - Explore AI Agents and intelligent applications\n",
    "   - Build F1 Q&A chatbots with your data\n",
    "\n",
    "### ğŸ¯ Best Practices Checklist:\n",
    "- âœ… **Start simple** with basic Bronze â†’ Silver â†’ Gold\n",
    "- âœ… **Add expectations gradually** as you understand your data\n",
    "- âœ… **Use descriptive table names** for clarity\n",
    "- âœ… **Document transformations** with comments\n",
    "- âœ… **Monitor data quality** trends over time\n",
    "- âœ… **Test expectations** before production deployment\n",
    "\n",
    "### ğŸ’¡ Pro Tips:\n",
    "- **ğŸ”§ Start with `@dlt.expect()`** to understand data patterns\n",
    "- **ğŸ“Š Use DLT dashboards** for quality monitoring\n",
    "- **âš¡ Leverage Serverless** for cost-effective execution\n",
    "- **ğŸ”„ Design for incremental processing** from day one\n",
    "\n",
    "**ğŸ”„ Your data pipelines are now production-ready! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06_Declarative_Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
